{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "GLOBAL_SEED = 7532\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(GLOBAL_SEED)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(GLOBAL_SEED)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.callbacks import Callback, EarlyStopping, History, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import BatchNormalization, Dense, Dropout, Conv2D, Flatten, Input, MaxPool2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('train_set_metadata_HMGD.csv')\n",
    "valid_set = pd.read_csv('valid_set_metadata_HMGD.csv')\n",
    "test_set = pd.read_csv('test_set_metadata_HMGD.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_MODEL_PATH = 'best_model.hdf5'\n",
    "\n",
    "INPUT_SHAPE = (320, 320, 3)\n",
    "\n",
    "LEARNING_RATE = 0.0002\n",
    "N_EPOCHS = 50\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the CNN model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=3, activation='relu',padding='same', \n",
    "                     input_shape=input_shape))\n",
    "    model.add(MaxPool2D(2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(48, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(MaxPool2D(2))\n",
    "    model.add(BatchNormalization())  \n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(MaxPool2D(2))\n",
    "    model.add(BatchNormalization())\n",
    " \n",
    "    model.add(Conv2D(96, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(MaxPool2D(2))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(MaxPool2D(2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(256, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(MaxPool2D(2))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(rate=0.5, seed=GLOBAL_SEED))\n",
    "    model.add(Dense(units=512, activation='relu'))\n",
    "    model.add(Dropout(rate=0.5, seed=GLOBAL_SEED))\n",
    "    model.add(Dense(units=256, activation='relu'))\n",
    "    model.add(Dropout(rate=0.5, seed=GLOBAL_SEED))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 320, 320, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 160, 160, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 160, 160, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 160, 160, 48)      13872     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 80, 80, 48)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 80, 80, 48)        192       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 80, 80, 64)        27712     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 40, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 40, 40, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 40, 40, 96)        55392     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 20, 20, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 20, 20, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 20, 20, 128)       110720    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 10, 10, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 10, 10, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 5, 5, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               3277312   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 3,915,153\n",
      "Trainable params: 3,913,905\n",
      "Non-trainable params: 1,248\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(INPUT_SHAPE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the class weights to be used during model training in order to mitigate the class imbalances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0949726587842759, 1: 0.9201873755187876}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_values = train_set['gender'].values\n",
    "classes = np.unique(class_values)\n",
    "\n",
    "weights = compute_class_weight(\n",
    "    'balanced', \n",
    "    classes, \n",
    "    class_values\n",
    ")\n",
    "class_weights = dict(zip(classes, weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 165400 images.\n",
      "Found 4176 images.\n",
      "Epoch 1/50\n",
      "5168/5168 [==============================] - 2795s 541ms/step - loss: 0.5657 - binary_accuracy: 0.7240 - val_loss: 0.4199 - val_binary_accuracy: 0.8123\n",
      "Epoch 2/50\n",
      "5168/5168 [==============================] - 2695s 521ms/step - loss: 0.3561 - binary_accuracy: 0.8499 - val_loss: 0.3560 - val_binary_accuracy: 0.8475\n",
      "Epoch 3/50\n",
      "5168/5168 [==============================] - 2703s 523ms/step - loss: 0.3155 - binary_accuracy: 0.8741 - val_loss: 0.3066 - val_binary_accuracy: 0.8736\n",
      "Epoch 4/50\n",
      "5168/5168 [==============================] - 2693s 521ms/step - loss: 0.2992 - binary_accuracy: 0.8821 - val_loss: 0.3215 - val_binary_accuracy: 0.8733\n",
      "Epoch 5/50\n",
      "5168/5168 [==============================] - 2693s 521ms/step - loss: 0.2903 - binary_accuracy: 0.8865 - val_loss: 0.3057 - val_binary_accuracy: 0.8728\n",
      "Epoch 6/50\n",
      "5168/5168 [==============================] - 2700s 523ms/step - loss: 0.2851 - binary_accuracy: 0.8892 - val_loss: 0.3139 - val_binary_accuracy: 0.8803\n",
      "Epoch 7/50\n",
      "5168/5168 [==============================] - 2701s 523ms/step - loss: 0.2819 - binary_accuracy: 0.8905 - val_loss: 0.2966 - val_binary_accuracy: 0.8743\n",
      "Epoch 8/50\n",
      "5168/5168 [==============================] - 2658s 514ms/step - loss: 0.2783 - binary_accuracy: 0.8920 - val_loss: 0.3011 - val_binary_accuracy: 0.8791\n",
      "Epoch 9/50\n",
      "5168/5168 [==============================] - 2640s 511ms/step - loss: 0.2756 - binary_accuracy: 0.8940 - val_loss: 0.3072 - val_binary_accuracy: 0.8731\n",
      "Epoch 10/50\n",
      "5168/5168 [==============================] - 2648s 512ms/step - loss: 0.2713 - binary_accuracy: 0.8959 - val_loss: 0.2999 - val_binary_accuracy: 0.8774\n",
      "Epoch 11/50\n",
      "5168/5168 [==============================] - 2651s 513ms/step - loss: 0.2697 - binary_accuracy: 0.8961 - val_loss: 0.2815 - val_binary_accuracy: 0.8875\n",
      "Epoch 12/50\n",
      "5168/5168 [==============================] - 2620s 507ms/step - loss: 0.2694 - binary_accuracy: 0.8970 - val_loss: 0.3041 - val_binary_accuracy: 0.8774\n",
      "Epoch 13/50\n",
      "5168/5168 [==============================] - 2601s 503ms/step - loss: 0.2674 - binary_accuracy: 0.8977 - val_loss: 0.2770 - val_binary_accuracy: 0.8902\n",
      "Epoch 14/50\n",
      "5168/5168 [==============================] - 2620s 507ms/step - loss: 0.2654 - binary_accuracy: 0.8981 - val_loss: 0.3010 - val_binary_accuracy: 0.8779\n",
      "Epoch 15/50\n",
      "5168/5168 [==============================] - 2556s 495ms/step - loss: 0.2657 - binary_accuracy: 0.8980 - val_loss: 0.2876 - val_binary_accuracy: 0.8868\n",
      "Epoch 16/50\n",
      "5168/5168 [==============================] - 2559s 495ms/step - loss: 0.2646 - binary_accuracy: 0.8990 - val_loss: 0.2806 - val_binary_accuracy: 0.8868\n",
      "Epoch 17/50\n",
      "5168/5168 [==============================] - 2529s 489ms/step - loss: 0.2640 - binary_accuracy: 0.8991 - val_loss: 0.2789 - val_binary_accuracy: 0.8839\n",
      "Epoch 18/50\n",
      "5168/5168 [==============================] - 2544s 492ms/step - loss: 0.2558 - binary_accuracy: 0.9023 - val_loss: 0.2794 - val_binary_accuracy: 0.8859\n",
      "Epoch 19/50\n",
      "5168/5168 [==============================] - 2629s 509ms/step - loss: 0.2541 - binary_accuracy: 0.9032 - val_loss: 0.2596 - val_binary_accuracy: 0.8962\n",
      "Epoch 20/50\n",
      "5168/5168 [==============================] - 2700s 523ms/step - loss: 0.2512 - binary_accuracy: 0.9040 - val_loss: 0.2739 - val_binary_accuracy: 0.8873\n",
      "Epoch 21/50\n",
      "5168/5168 [==============================] - 2706s 524ms/step - loss: 0.2506 - binary_accuracy: 0.9042 - val_loss: 0.2677 - val_binary_accuracy: 0.8945\n",
      "Epoch 22/50\n",
      "5168/5168 [==============================] - 2576s 499ms/step - loss: 0.2505 - binary_accuracy: 0.9040 - val_loss: 0.2761 - val_binary_accuracy: 0.8897\n",
      "Epoch 23/50\n",
      "5168/5168 [==============================] - 2567s 497ms/step - loss: 0.2503 - binary_accuracy: 0.9040 - val_loss: 0.2681 - val_binary_accuracy: 0.8912\n",
      "Epoch 24/50\n",
      "5168/5168 [==============================] - 2603s 504ms/step - loss: 0.2447 - binary_accuracy: 0.9060 - val_loss: 0.2634 - val_binary_accuracy: 0.8933\n",
      "Epoch 25/50\n",
      "5168/5168 [==============================] - 2611s 505ms/step - loss: 0.2447 - binary_accuracy: 0.9059 - val_loss: 0.2736 - val_binary_accuracy: 0.8907\n",
      "Epoch 26/50\n",
      "5168/5168 [==============================] - 2701s 523ms/step - loss: 0.2433 - binary_accuracy: 0.9065 - val_loss: 0.2691 - val_binary_accuracy: 0.8958\n",
      "Epoch 27/50\n",
      "5168/5168 [==============================] - 2746s 531ms/step - loss: 0.2431 - binary_accuracy: 0.9066 - val_loss: 0.2681 - val_binary_accuracy: 0.8921\n",
      "Epoch 28/50\n",
      "5168/5168 [==============================] - 2749s 532ms/step - loss: 0.2399 - binary_accuracy: 0.9075 - val_loss: 0.2646 - val_binary_accuracy: 0.8936\n",
      "Epoch 29/50\n",
      "5168/5168 [==============================] - 2792s 540ms/step - loss: 0.2405 - binary_accuracy: 0.9071 - val_loss: 0.2653 - val_binary_accuracy: 0.8953\n"
     ]
    }
   ],
   "source": [
    "# Create and compile the model\n",
    "adam = Adam(\n",
    "    lr=LEARNING_RATE\n",
    ")\n",
    "model.compile(\n",
    "    optimizer=adam, \n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy']\n",
    ")\n",
    "\n",
    "# Initialize callbacks\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'model_custom_small_epoch_{epoch:03d}.hdf5', \n",
    "    monitor='val_loss', \n",
    "    save_best_only=False, \n",
    "    save_weights_only=False\n",
    ")\n",
    "lr_reduction = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.5, \n",
    "    patience=4\n",
    ")\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=10\n",
    ")    \n",
    "callback_list = [checkpoint, lr_reduction, early_stopping]\n",
    "\n",
    "# generate and augment training and validation data\n",
    "data_generator = ImageDataGenerator(\n",
    "    rotation_range=20, \n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range=0.2, \n",
    "    horizontal_flip=True  \n",
    ")\n",
    "train_data_generator = data_generator.flow_from_dataframe(\n",
    "    dataframe=train_set, \n",
    "    directory='imdb_crop/_all_photos/',\n",
    "    x_col='photo_path',\n",
    "    y_col='gender',\n",
    "    target_size=(320, 320),\n",
    "    class_mode='other',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=GLOBAL_SEED\n",
    ")\n",
    "valid_data_generator = data_generator.flow_from_dataframe(\n",
    "    dataframe=valid_set, \n",
    "    directory='imdb_crop/_all_photos/',\n",
    "    x_col='photo_path',\n",
    "    y_col='gender',\n",
    "    target_size=(320, 320),\n",
    "    class_mode='other',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=GLOBAL_SEED\n",
    ")\n",
    "\n",
    "train_steps_per_epoch = train_data_generator.n//train_data_generator.batch_size\n",
    "valid_steps_per_epoch = valid_data_generator.n//valid_data_generator.batch_size\n",
    "\n",
    "#fit the model\n",
    "history = model.fit_generator(\n",
    "    generator=train_data_generator,\n",
    "    steps_per_epoch=train_steps_per_epoch, \n",
    "    epochs=N_EPOCHS,\n",
    "    callbacks=callback_list,\n",
    "    validation_data=valid_data_generator,\n",
    "    validation_steps=valid_steps_per_epoch,\n",
    "    class_weight=class_weights,\n",
    "    workers=4, \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7621 images.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.28291906248427073, 0.889253378821677]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_data_generator = ImageDataGenerator().flow_from_dataframe(\n",
    "    dataframe=test_set, \n",
    "    directory='imdb_crop/_all_photos/',\n",
    "    x_col='photo_path',\n",
    "    y_col='gender',\n",
    "    target_size=(320, 320),\n",
    "    class_mode='other',\n",
    "    batch_size=1,\n",
    "    seed=GLOBAL_SEED,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "best_model = load_model('model_custom_small_epoch_019.hdf5')\n",
    "best_model.evaluate_generator(generator=evaluation_data_generator, steps=len(test_set))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
